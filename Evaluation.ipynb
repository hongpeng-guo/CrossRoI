{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, cv2\n",
    "from os import confstr_names\n",
    "import numpy as np\n",
    "from numpy.lib.npyio import _savez_compressed_dispatcher\n",
    "import General as general\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import Reducto as reducto\n",
    "from reducto.differencer import AreaDiff\n",
    "\n",
    "\n",
    "# environment & macro definations\n",
    "FRAME_RATE = general.FRAME_RATE\n",
    "WORKSAPCE = general.WORKSAPCE\n",
    "DATA_PATH = general.DATA_PATH\n",
    "GT_PATH = general.GT_PATH\n",
    "TRACK_PATH = general.TRACK_PATH\n",
    "ts_base = general.ts_base\n",
    "cameras = general.cameras\n",
    "frame_diff = general.frame_diff\n",
    "\n",
    "# detection environment from my sbnet-yolov3\n",
    "DET_DIR = \"../tensorflow-yolov3\"\n",
    "\n",
    "\n",
    "def time_to_det_bbox(cam_name):\n",
    "    result = {}\n",
    "    for line in open(DET_DIR + '/' + 'det_' + cam_name + '.txt', 'r').readlines():\n",
    "        frame_id, left, top, right, buttom, confidence = [float(each) for each in line.split(' ')]\n",
    "        frame_id = round(frame_id)\n",
    "\n",
    "        if frame_id + 1 not in result:\n",
    "            result[frame_id + 1] = [(left, top, right - left, buttom - top)]\n",
    "        else:\n",
    "            result[frame_id + 1].append((left, top, right - left, buttom - top))\n",
    "    return result\n",
    "\n",
    "\n",
    "def time_to_baseline_bbox(cam_name):\n",
    "    # print(general.cameras_shape[cam_name][1])\n",
    "    result = {}\n",
    "    for line in open(DET_DIR + '/' + 'baseline_' + cam_name + '.txt', 'r').readlines():\n",
    "        frame_id, left, top, right, buttom, confidence = [float(each) for each in line.split(' ')]\n",
    "        frame_id = round(frame_id)\n",
    "\n",
    "        # remove low confidence object \n",
    "        if confidence < 0.7: continue\n",
    "        # remove margin none complete object\n",
    "        if left < 150 or right + 150 > general.cameras_shape[cam_name][1] or \\\n",
    "            top < 150 or buttom + 150 > general.cameras_shape[cam_name][0]: continue\n",
    "        # remove too small object from\n",
    "        # if (right - left) * (buttom - top) < 800: continue\n",
    "\n",
    "        if frame_id + 1  not in result:\n",
    "            result[frame_id + 1] = [(left, top, right - left, buttom - top)]\n",
    "        else:\n",
    "            result[frame_id + 1].append((left, top, right - left, buttom - top))\n",
    "    return result\n",
    "\n",
    "\n",
    "def time_to_didi_reid_bbox_obj(cam_name):\n",
    "    result = {}\n",
    "    for line in open(WORKSAPCE +  'track1.txt', 'r').readlines():\n",
    "        camera, obj_id, frame_id, left, top, width, height, _, _ = [round(int(each)) for each in line.split(' ')]\n",
    "        if camera > 5: break\n",
    "        if camera != int(cam_name[-1]): continue\n",
    "        if frame_id  not in result:\n",
    "            result[frame_id] = [(left, top, width, height, obj_id)]\n",
    "        else:\n",
    "            result[frame_id].append((left, top, width, height, obj_id))\n",
    "    return result\n",
    "\n",
    "\n",
    "def time_to_gt_bbox_obj(cam_name):\n",
    "    result = {}\n",
    "    for line in open(WORKSAPCE + DATA_PATH + cam_name + '/' + GT_PATH, 'r').readlines():\n",
    "        frame_id, obj_id, left, top, width, height, _, _, _, _ = [round(int(each)) for each in line.split(',')]\n",
    "        if frame_id  not in result:\n",
    "            result[frame_id] = [(left, top, width, height, obj_id)]\n",
    "        else:\n",
    "            result[frame_id].append((left, top, width, height, obj_id))\n",
    "    return result\n",
    "\n",
    "\n",
    "def gt_time_bbox_obbj_Kalman_filter(cam_name, input_dict):\n",
    "    result = {}\n",
    "    obj_to_time_bbox = {}\n",
    "    for frame_id in input_dict:\n",
    "        for rect_obj in input_dict[frame_id]:\n",
    "            rect, obj_id = rect_obj[:4], rect_obj[-1]\n",
    "            if obj_id not in obj_to_time_bbox:\n",
    "                obj_to_time_bbox[obj_id] = {frame_id: rect}\n",
    "            else:\n",
    "                obj_to_time_bbox[obj_id][frame_id] = rect\n",
    "\n",
    "    for obj_id in obj_to_time_bbox:\n",
    "        duration_map = OrderedDict(sorted(obj_to_time_bbox[obj_id].items()))\n",
    "        exist_frames = list(duration_map.keys())\n",
    "        for i, frame_id in enumerate(exist_frames):\n",
    "            if i == 0: continue\n",
    "            if exist_frames[i-1] + 1 == frame_id: continue\n",
    "            for add_frame_id in range(exist_frames[i-1] + 1, frame_id):\n",
    "                previous_value = tuple([each * (frame_id - add_frame_id) for each in duration_map[exist_frames[i-1]]])\n",
    "                future_value = tuple([each * (add_frame_id - exist_frames[i-1]) for each in duration_map[frame_id]])\n",
    "                l, t, w, h = tuple([(previous_value[j] + future_value[j]) // (frame_id - exist_frames[i-1]) for j in range(4)])\n",
    "                l, t, w, h = max(l, 0), max(t, 0), min(general.cameras_shape[cam_name][1]-l, w), min(general.cameras_shape[cam_name][0]-t, h)\n",
    "                obj_to_time_bbox[obj_id][add_frame_id] = (l, t, w, h)\n",
    "        \n",
    "        if len(exist_frames) == 1: continue\n",
    "\n",
    "        begin = max(0, exist_frames[0] - 20)\n",
    "        for add_frame_id in range(begin, exist_frames[0]):\n",
    "            near_value = tuple([each * (exist_frames[1] - add_frame_id) for each in duration_map[exist_frames[0]]])\n",
    "            far_value = tuple([each * (exist_frames[0] - add_frame_id) for each in duration_map[exist_frames[1]]])\n",
    "            l, t, w, h = ((near_value[i] - far_value[i])  for i in range(4))\n",
    "            l, t, w, h = max(l, 0), max(t, 0), min(general.cameras_shape[cam_name][1]-l, w), min(general.cameras_shape[cam_name][0]-t, h)\n",
    "            obj_to_time_bbox[obj_id][add_frame_id] = (l, t, w, h)\n",
    " \n",
    "        end = exist_frames[-1] + 20\n",
    "        for add_frame_id in range(exist_frames[-1], end + 1):\n",
    "            near_value = tuple([each * (-exist_frames[-2] + add_frame_id) for each in duration_map[exist_frames[-1]]])\n",
    "            far_value = tuple([each * (-exist_frames[-1] + add_frame_id) for each in duration_map[exist_frames[-2]]])\n",
    "            l, t, w, h = ((near_value[i] - far_value[i])  for i in range(4))\n",
    "            l, t, w, h = max(l, 0), max(t, 0), min(general.cameras_shape[cam_name][1]-l, w), min(general.cameras_shape[cam_name][0]-t, h)\n",
    "            obj_to_time_bbox[obj_id][add_frame_id] = (l, t, w, h)\n",
    " \n",
    "    for obj_id in obj_to_time_bbox:\n",
    "        for frame_id in obj_to_time_bbox[obj_id]:\n",
    "            rect = obj_to_time_bbox[obj_id][frame_id]\n",
    "            if frame_id not in result:\n",
    "                result[frame_id] = [rect + (obj_id,)]\n",
    "            else:\n",
    "                result[frame_id].append(rect + (obj_id,))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def time_to_track_bbox_obj(cam_name):\n",
    "    result = {}\n",
    "\n",
    "    track_id_time_to_bbox = {}\n",
    "    for line in open(WORKSAPCE + DATA_PATH + cam_name + '/' + TRACK_PATH, 'r').readlines():\n",
    "        frame_id, obj_id, left, top, width, height, _, _, _, _ = [round(float(each)) for each in line.split(',')]\n",
    "        if obj_id  not in track_id_time_to_bbox:\n",
    "            track_id_time_to_bbox[obj_id] = {frame_id: (left, top, width, height)}\n",
    "        else:\n",
    "            track_id_time_to_bbox[obj_id][frame_id] = (left, top, width, height)\n",
    "\n",
    "    total_obj = len(track_id_time_to_bbox)\n",
    "    re_id_obj_count = 0\n",
    "\n",
    "    gt_time_to_bbox_obj = time_to_gt_bbox_obj(cam_name)\n",
    "    for obj_id in track_id_time_to_bbox:\n",
    "        reid_candidates = {}\n",
    "        for frame_id in track_id_time_to_bbox[obj_id]:\n",
    "            if frame_id not in gt_time_to_bbox_obj: \n",
    "                continue\n",
    "            for gt_bbox_obj in gt_time_to_bbox_obj[frame_id]:\n",
    "                track_rect = track_id_time_to_bbox[obj_id][frame_id]\n",
    "                gt_bbox, gt_obj = gt_bbox_obj[:4], gt_bbox_obj[-1]\n",
    "                IoU_score = general.IoU(track_rect, gt_bbox)\n",
    "                if IoU_score > 0.3:\n",
    "                    if gt_obj not in reid_candidates:\n",
    "                        reid_candidates[gt_obj] = IoU_score\n",
    "                    else:\n",
    "                        reid_candidates[gt_obj] += IoU_score\n",
    "\n",
    "        if len(reid_candidates) == 0:\n",
    "            new_obj_id = -1\n",
    "        else:\n",
    "            new_obj_id, obj_score = max(reid_candidates, key=reid_candidates.get), max(reid_candidates.keys())\n",
    "            if obj_score < 0.8:\n",
    "                new_obj_id = -1\n",
    "            else:\n",
    "                re_id_obj_count += 1\n",
    "\n",
    "        for frame_id in track_id_time_to_bbox[obj_id]:\n",
    "            bbox = track_id_time_to_bbox[obj_id][frame_id]\n",
    "            if frame_id not in result:\n",
    "                result[frame_id] = [bbox + (new_obj_id, )]\n",
    "            else:\n",
    "                result[frame_id].append(bbox + (new_obj_id, ))\n",
    "    \n",
    "    print(cam_name, total_obj, re_id_obj_count)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compare_baseline_det_bbox(cam_name):\n",
    "    det_t_to_bbox = time_to_det_bbox(cam_name)\n",
    "    baseline_t_to_bbox = time_to_baseline_bbox(cam_name)\n",
    "    time = baseline_t_to_bbox.keys()\n",
    "    same_result, diff_result = {t: [] for t in time}, {t: [] for t in time}\n",
    "    for t in time:\n",
    "        if t not in det_t_to_bbox:\n",
    "            diff_result[t] = baseline_t_to_bbox[t]\n",
    "            continue\n",
    "        for baseline_rect in baseline_t_to_bbox[t]:\n",
    "            IoU_score = 0\n",
    "            for det_rect in det_t_to_bbox[t]:\n",
    "                IoU_score = max(IoU_score, general.IoU(baseline_rect, det_rect))\n",
    "            if IoU_score < 0.3:\n",
    "                diff_result[t].append(baseline_rect)\n",
    "            else:\n",
    "                same_result[t].append(baseline_rect)\n",
    "    return same_result, diff_result\n",
    "\n",
    "\n",
    "def assign_id(id_dict, target_dict):\n",
    "    time = target_dict.keys()\n",
    "    for t in time:\n",
    "        if t not in id_dict:\n",
    "            bboxes = target_dict[t]\n",
    "            id_bboxes = [each + (-1,) for each in bboxes]\n",
    "            target_dict[t] = id_bboxes\n",
    "            continue\n",
    "        for idx, target_rect in enumerate(target_dict[t]):\n",
    "            best_fit_id, IoU_score = -1, 0\n",
    "            for gt_rect_id in id_dict[t]:\n",
    "                gt_rect, id = gt_rect_id[:4], gt_rect_id[-1]\n",
    "                IoU_tmp = general.IoU(target_rect, gt_rect)\n",
    "                if IoU_tmp < 0.2: continue\n",
    "                if IoU_tmp > IoU_score:\n",
    "                    IoU_score = IoU_tmp\n",
    "                    best_fit_id = id\n",
    "            target_dict[t][idx] = target_dict[t][idx] + (best_fit_id,)\n",
    "    return target_dict\n",
    "\n",
    "def assign_ID_time_to_bbox(cam_name):\n",
    "    same_result, diff_result = compare_baseline_det_bbox(cam_name)\n",
    "    gt_time_to_obj_id = time_to_gt_bbox_obj(cam_name)\n",
    "    gt_time_to_obj_id = gt_time_bbox_obbj_Kalman_filter(cam_name, gt_time_to_obj_id)\n",
    "\n",
    "    return assign_id(gt_time_to_obj_id, same_result),\\\n",
    "           assign_id(gt_time_to_obj_id, diff_result)\n",
    "\n",
    "\n",
    "def car_counting_Baseline_Roi(cameras, time_window):\n",
    "\n",
    "    cameras_same_t_to_bbox_id = {cam: {} for cam in cameras}\n",
    "    cameras_diff_t_to_bbox_id = {cam: {} for cam in cameras}\n",
    "\n",
    "    for cam_name in cameras:\n",
    "        same_t_to_bbox_id, diff_t_to_bbox_id = assign_ID_time_to_bbox(cam_name)\n",
    "        cameras_same_t_to_bbox_id[cam_name] = same_t_to_bbox_id\n",
    "        cameras_diff_t_to_bbox_id[cam_name] = diff_t_to_bbox_id\n",
    "\n",
    "    baseline_result = [0 for _ in range(time_window[1] - time_window[0])]\n",
    "    det_result = [0 for _ in range(time_window[1] - time_window[0])]\n",
    "\n",
    "    evaluate_interval, interval_shared_stack = 3, []\n",
    "\n",
    "    for t in range(time_window[0], time_window[1]):\n",
    "        unique_count, shared_set = 0, set()\n",
    "        for cam_name in cameras:\n",
    "            real_t = t - frame_diff[cam_name]\n",
    "            if real_t not in cameras_same_t_to_bbox_id[cam_name]: continue\n",
    "            for _, _, _, _, id in cameras_same_t_to_bbox_id[cam_name][real_t]:\n",
    "                if id == -1: \n",
    "                    unique_count += 1\n",
    "                else:\n",
    "                    shared_set.add(id)\n",
    "        det_result[t - time_window[0]] = unique_count + len(shared_set)\n",
    "\n",
    "        if len(interval_shared_stack) == evaluate_interval:\n",
    "            interval_shared_stack.pop(0)\n",
    "        interval_shared_stack.append(shared_set)\n",
    "\n",
    "        diff_unique_count = 0\n",
    "        for cam_name in cameras:\n",
    "            real_t = t - frame_diff[cam_name]\n",
    "            if real_t not in cameras_diff_t_to_bbox_id[cam_name]: continue\n",
    "            for left, top, width, height, id in cameras_diff_t_to_bbox_id[cam_name][real_t]:\n",
    "                # baseframe = general.get_frame(cam_name, real_t - 1)\n",
    "                # left, top, width, height = int(left), int(top), int(width), int(height)\n",
    "                # print(left, top, left+width, top+height)\n",
    "                if id == -1: \n",
    "                    diff_unique_count += 1\n",
    "                    continue\n",
    "                elif id not in set.union(* interval_shared_stack):\n",
    "                    diff_unique_count += 1\n",
    "                    shared_set.add(id)\n",
    "                    continue\n",
    "                else:\n",
    "                    continue\n",
    "                baseframe = cv2.cv2.rectangle(baseframe, (left, top), (left + width, top + height), (255, 0, 0), 3)\n",
    "                cv2.imshow('image', baseframe)\n",
    "                cv2.waitKey()\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "        baseline_result[t - time_window[0]] = diff_unique_count + det_result[t - time_window[0]]\n",
    "\n",
    "    diff = [max( baseline_result[i] - det_result[i], 0 ) for i in range(len(baseline_result))]\n",
    "\n",
    "    print(sum(diff), sum(baseline_result), sum(diff)/ sum(baseline_result))\n",
    "    plt.plot(baseline_result)\n",
    "    plt.plot(diff)\n",
    "    plt.show()\n",
    "\n",
    "    return baseline_result, det_result\n",
    "\n",
    "\n",
    "# Note that selected_frames are 1 indexed.\n",
    "def car_counting_Reducto(cameras, selected_frames, time_window):\n",
    "    cameras_t_to_bbox_id = {cam: {} for cam in cameras}\n",
    "    \n",
    "    for cam_name in cameras: \n",
    "        baseline_t_to_bbox = time_to_baseline_bbox(cam_name)\n",
    "        gt_time_to_obj_id = time_to_gt_bbox_obj(cam_name)\n",
    "        gt_time_to_obj_id = gt_time_bbox_obbj_Kalman_filter(cam_name, gt_time_to_obj_id)\n",
    "    \n",
    "        cameras_t_to_bbox_id[cam_name] = assign_id(gt_time_to_obj_id, baseline_t_to_bbox)\n",
    "\n",
    "    baseline_result = [0 for _ in range(time_window[1] - time_window[0])]\n",
    "\n",
    "    evaluate_interval, interval_shared_stack = 3, []\n",
    "\n",
    "    prev_det_frame = {cam_name: time_window[0] for cam_name in cameras}\n",
    "\n",
    "    for t in range(time_window[0], time_window[1]):\n",
    "        unique_count, shared_set = 0, set()\n",
    "        for cam_name in cameras:\n",
    "            if t + 1 in selected_frames[cam_name]:\n",
    "                real_t = t - frame_diff[cam_name]\n",
    "                prev_det_frame[cam_name] = t\n",
    "            else:\n",
    "                real_t = prev_det_frame[cam_name] - frame_diff[cam_name]\n",
    "\n",
    "            if real_t not in cameras_t_to_bbox_id[cam_name]: continue\n",
    "            for _, _, _, _, id in cameras_t_to_bbox_id[cam_name][real_t]:\n",
    "                if id == -1: \n",
    "                    unique_count += 1\n",
    "                else:\n",
    "                    shared_set.add(id)\n",
    "        baseline_result[t - time_window[0]] = unique_count + len(shared_set)\n",
    "\n",
    "        if len(interval_shared_stack) == evaluate_interval:\n",
    "            interval_shared_stack.pop(0)\n",
    "        interval_shared_stack.append(shared_set)\n",
    "\n",
    "    return baseline_result\n",
    "\n",
    "\n",
    "# Note that selected_frames are 1 indexed.\n",
    "def car_counting_ReductoRoi(cameras, selected_frames, time_window):\n",
    "\n",
    "    cameras_same_t_to_bbox_id = {cam: {} for cam in cameras}\n",
    "\n",
    "    for cam_name in cameras:\n",
    "        same_t_to_bbox_id, _ = assign_ID_time_to_bbox(cam_name)\n",
    "        cameras_same_t_to_bbox_id[cam_name] = same_t_to_bbox_id\n",
    "\n",
    "    det_result = [0 for _ in range(time_window[1] - time_window[0])]\n",
    "\n",
    "    evaluate_interval, interval_shared_stack = 3, []\n",
    "\n",
    "    prev_det_frame = {cam_name: time_window[0] for cam_name in cameras}\n",
    "\n",
    "    for t in range(time_window[0], time_window[1]):\n",
    "        unique_count, shared_set = 0, set()\n",
    "        for cam_name in cameras:\n",
    "            if t + 1 in selected_frames[cam_name]:\n",
    "                real_t = t - frame_diff[cam_name]\n",
    "                prev_det_frame[cam_name] = t\n",
    "            else:\n",
    "                real_t = prev_det_frame[cam_name] - frame_diff[cam_name]\n",
    "\n",
    "            if real_t not in cameras_same_t_to_bbox_id[cam_name]: continue\n",
    "            for _, _, _, _, id in cameras_same_t_to_bbox_id[cam_name][real_t]:\n",
    "                if id == -1: \n",
    "                    unique_count += 1\n",
    "                else:\n",
    "                    shared_set.add(id)\n",
    "        det_result[t - time_window[0]] = unique_count + len(shared_set)\n",
    "\n",
    "        if len(interval_shared_stack) == evaluate_interval:\n",
    "            interval_shared_stack.pop(0)\n",
    "        interval_shared_stack.append(shared_set)\n",
    "\n",
    "    return det_result\n",
    "\n",
    "\n",
    "# get selected frames in reducto retting.\n",
    "def get_reducto_selected_frames(cameras_t_to_count, roi=False):\n",
    "    result = {}\n",
    "\n",
    "    for cam_name in cameras_t_to_count:\n",
    "        bbox_count_dict = {}\n",
    "        for i in range(0, 1800):\n",
    "            if i not in cameras_t_to_count[cam_name]:\n",
    "                bbox_count_dict[i+1] = 0\n",
    "            else:\n",
    "                bbox_count_dict[i+1] = cameras_t_to_count[cam_name][i]\n",
    "        if roi:\n",
    "            video_path = 'videos/croped_' + cam_name + '.mp4'\n",
    "        else:\n",
    "            video_path = 'videos/h264_' + cam_name + '.mp4'\n",
    "\n",
    "        diff_vectors = reducto.get_segmented_diff_vectors(video_path, segment_limit=90)\n",
    "        train_vectors, test_vectors = diff_vectors[:30], diff_vectors[30:] \n",
    "\n",
    "        thresholds = [0.0, 0.002, 0.004, 0.006, 0.008, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]\n",
    "        diff_results = reducto.get_segmented_diff_results(\n",
    "                                train_vectors, \n",
    "                                thresholds)\n",
    "        evaluations = reducto.get_segmented_evaluations(diff_results, bbox_count_dict)\n",
    "\n",
    "        thresh_map = reducto.generate_hashmap(evaluations, train_vectors)\n",
    "\n",
    "        selected_frames = reducto.generate_test_result(test_vectors, 600, bbox_count_dict, thresh_map)\n",
    "\n",
    "        result[cam_name] = selected_frames\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras_same_t_to_bbox_id = {cam: {} for cam in cameras}\n",
    "cameras_diff_t_to_bbox_id = {cam: {} for cam in cameras}\n",
    "\n",
    "for cam_name in cameras:\n",
    "    same_t_to_bbox_id, diff_t_to_bbox_id = assign_ID_time_to_bbox(cam_name)\n",
    "    cameras_same_t_to_bbox_id[cam_name] = same_t_to_bbox_id\n",
    "    cameras_diff_t_to_bbox_id[cam_name] = diff_t_to_bbox_id\n",
    "\n",
    "roi_t_to_count = { cam_name: { t: len(cameras_same_t_to_bbox_id[cam_name][t]) \\\n",
    "                               for t in cameras_same_t_to_bbox_id[cam_name]} \\\n",
    "                   for cam_name in cameras_same_t_to_bbox_id } \n",
    "\n",
    "baseline_t_to_count = { cam_name: { t: len(cameras_same_t_to_bbox_id[cam_name][t]) + roi_t_to_count[cam_name][t]\\\n",
    "                               for t in cameras_same_t_to_bbox_id[cam_name]} \\\n",
    "                   for cam_name in cameras_same_t_to_bbox_id } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e815bd9e6b5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroi_selected_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reducto_selected_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_t_to_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbaseline_selected_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reducto_selected_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline_t_to_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-a285c7fd2643>\u001b[0m in \u001b[0;36mget_reducto_selected_frames\u001b[0;34m(cameras_t_to_count, roi)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'videos/h264_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcam_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0mdiff_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreducto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_segmented_diff_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/DelegationGraph/Reducto.py\u001b[0m in \u001b[0;36mget_segmented_diff_vectors\u001b[0;34m(video_path, segment_size, segment_limit)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_segmented_diff_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0marea_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAreaDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdiff_vector_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea_dp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_diff_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     diff_vectors = [diff_vector_all[i:i+segment_size] \\\n\u001b[1;32m     12\u001b[0m                     for i in range(0, len(diff_vector_all), segment_size)]\n",
      "\u001b[0;32m~/Desktop/research/DelegationGraph/reducto/differencer/diff_processor.py\u001b[0m in \u001b[0;36mget_diff_vector\u001b[0;34m(self, video_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdiff_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mVideoProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mprev_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mprev_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/research/DelegationGraph/reducto/video_processor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0m_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roi_selected_frames = get_reducto_selected_frames(roi_t_to_count, roi=True)\n",
    "\n",
    "baseline_selected_frames = get_reducto_selected_frames(baseline_t_to_count, roi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_res, roi_res = car_counting_Baseline_Roi(cameras, [600, 1800])\n",
    "\n",
    "reducto_res = car_counting_Reducto(cameras, baseline_selected_frames, [600, 1800])\n",
    "\n",
    "reductoroi_res = car_counting_ReductoRoi(cameras, roi_selected_frames, [600, 1800])\n",
    "\n",
    "roi_err = [abs(baseline_res[i] - roi_res[i]) for i in range(len(baseline_res))]\n",
    "reducto_err = [abs(baseline_res[i] - reducto_res[i]) for i in range(len(baseline_res))]\n",
    "reductoroi_err = [abs(baseline_res[i] - reductoroi_res[i]) for i in range(len(baseline_res))]\n",
    "\n",
    "print(sum(baseline_res) / len(baseline_res))\n",
    "print(sum(roi_err) / sum(baseline_res))\n",
    "print(sum(reducto_err) / sum(baseline_res))\n",
    "print(sum(reductoroi_err) / sum(baseline_res))\n",
    "\n",
    "plt.plot(roi_err)\n",
    "plt.show()\n",
    "plt.plot(reducto_err)\n",
    "plt.show()\n",
    "plt.plot(reductoroi_err)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbasecondab3efe469cc3b487dac7dc0c38dc4461c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
